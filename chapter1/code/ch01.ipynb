{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k7svdNvOoZYD"
      },
      "source": [
        "# Introduction to Deep Learning\n",
        "\n",
        "\n",
        "Our goal is to help you gain beginning deep learning skills through Python coding examples using Tensoflow 2.0. We begin by explaining the concept of deep learning, what machine learning algorithms do, how deep learning differs from machine learning, and how to implement deep learning examples.\n",
        "\n",
        "**Deep learning** is a class of machine learning algorithms that uses multiple (successive) layers to progressively extract higher level features from the raw input. That is, deep learning emphasizes learning successive layers of increasingly meaningful representations from the data. In image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YhaxbqM3oeP4"
      },
      "source": [
        "# Neural Networks\n",
        "\n",
        "In deep learning, the successive layers are almost always learned by models called neural networks. **Neural networks** are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input.\n",
        "\n",
        "A layer is the core building block in deep learning. A **layer** is a container that usually receives weighted input, transforms it with a set of mostly non-linear functions and then passes these values as output to the next layer.\n",
        "\n",
        "A layer can be thought of as a data-processing module that acts as a filter for data. Data goes into a layer and it comes out in a more useful form. Layers extract representations out of the data fed into them. Of course, we hope that the representations are meaningful to help us solve the problem at hand. This is why deep learning takes a lot of practice and experimentation to reap benefits.\n",
        "\n",
        "A very common problem that deep learning is used to solve is the identification of digits 0 through 9. So, we can create a neural network composed of successive layers to help us automatically predict a digit from its image data.\n",
        "\n",
        "For example, suppose we have an image of the digit 8 in our data set. If our neural network is robust, it should be able to correctly predict that the digit is 8 from the image data without human intervention! That is, the computer model (the neural network) is able to predict with a high degree of accuracy images of digits. Of course, humans can easily distinguish digits between 0 and 9, but the ability of a computer model to do this is amazing and at the heart of what deep learning is all about.\n",
        "\n",
        "A neural network is a collection of **neurons** with **synapses** connecting them. The collection is organized into three main parts:\n",
        "\n",
        "* the input layer\n",
        "* the hidden layer\n",
        "* the output layer\n",
        "\n",
        "When training a neural network, data is initially passed to the **input layer**. The input layer then passes the data through the activation function before passing it on to the first hidden layer. An **activation function** defines the output of a neuron given an input or set of inputs.\n",
        "\n",
        "A **hidden layer** is a layer in between input layers and output layers where artificial neurons take in a set of weighted inputs and produce an output through an activation function. A network can have multiple hidden layers.\n",
        "\n",
        "The **output layer** produces the result for given inputs. It is the place where all the computation is done.\n",
        "\n",
        "Neurons tend to be remarkably simple, with nothing but a floating point value, an input, and an output. That float is what we refer to as the **weight** of a neuron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sVr8ZtqholoW"
      },
      "source": [
        "# Learning Representations from Data\n",
        "\n",
        "Machine learning algorithms discover rules to execute a data processing task. So, to conduct machine learning we need three things:\n",
        "\n",
        "1. input data points\n",
        "2. examples of expected output\n",
        "3. a way to measure whether the algorithm is performing well\n",
        "\n",
        "Input data points are data of some kind. An example of input data could be pictures. Image recognition in deep learning requires pictures. Of course the deep learning models require numeric data, which means that the pictures must be transformed in some way. We will cover how to transform such data later in the chapter.\n",
        "\n",
        "To make predictions from data in deep learning, we need examples of expected output. So, the data must contain a representation of each data example and what each data example represents. For example, when predicting digits, the data must contain representations of each digit and what the digit represents. Specifically, if an example from the data is the digit 9 we must have the representation of the digit 9 and a target value of 9. We will cover how to represent a digit and its target value later in the chapter.\n",
        "\n",
        "Finally, we need to determine the distance (loss) between the algorithm's current output and its expected output. This distance is often called loss or error. The **loss** is used as feedback to adjust the way the algorithm works. This adjustment is called **learning**. For example, if our neural network model predicts that a digit is 3 but it is really an 8 our model has at least some loss (or error). That is, there is some distance between what the model predicted and its expected output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LviD1U4Eop8c"
      },
      "source": [
        "# Goal of Machine Learning\n",
        "\n",
        "The goal of machine learning models is to transform input data into **meaningful** outputs. This transformation is how the model learns from exposure to known examples of inputs and outputs. As such, the central problem in machine learning and deep learning is to *meaningfully transform data*. If we can meaningfully transform data, we can learn useful *representations* of the input data that get us closer to the expected output.\n",
        "\n",
        "Representations of data offer a different way to look at it. For example, an image of a digit can be represented as a 2 x 2 matrix of 1's and 0's.\n",
        "\n",
        "Learning in the context of machine learning describes an automatic search process for better representations. Deep learning is a specific subfield of machine learning that emphasizes learning successive *layers* of increasingly meaningful representations.\n",
        "\n",
        "Simply, we want to learn from our dataset so we can reliably predict from new (unseen) data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ykEk1T7ovbv"
      },
      "source": [
        "# Control a Neural Network\n",
        "\n",
        "To control the output of a neural network, we need to measure how far this output is from what we expected. So, we introduce a loss function for this purpose. The **loss function** takes the predictions of the network and the true target and computes a distance score. The **true target** is what we wanted the network to output. That is, what we expect. The **distance score** captures how well the network has done on this specific set of data.\n",
        "\n",
        "Simply, the **distance score** measures the difference between our expected outcome and the actual outcome. This distance is commonly referred to as **loss**, **cost** or **error**. We want our neural network to minimize loss. That is, we want our neural network to minimize the difference between our predictions and the actual values.\n",
        "\n",
        "We can refer to what we want from our neural network in several ways:\n",
        "\n",
        "* minimize loss\n",
        "* minimize cost\n",
        "* minimize error\n",
        "* minimize the loss function\n",
        "* minimize the cost function\n",
        "\n",
        "The loss function score is used as a feedback signal to adjust the value of the model in a direction that will lower loss. The higher the loss, the worse our model is performing. To adjust the loss function score, we use an optimizer. An **optimizer** is used to improve speed and performance when training a specific model. An optimizer implements a backpropagation algorithm. The **backpropagation algorithm** is the *central algorithm* in deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kkKVMYGXo0LU"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "A neural network propagates the signal of the input data forward through its parameters towards the moment of decision. It then backpropagates information about the error in reverse through the network so that it can alter the parameters. This happens step by step:\n",
        "\n",
        "* The network makes a guess about data, using its parameters\n",
        "* The network’s progress is measured with a loss function\n",
        "* The error is backpropagated to adjust the wrong-headed parameters\n",
        "\n",
        "**Backpropagation** takes the error associated with a wrong guess by a neural network and uses that error to adjust the neural network’s parameters in the direction of less error. Specifically, backpropogation starts with the final loss value (or error), works backwards from the top layers to the bottom layers, and applies the chain rule (from calculus) to compute the contribution that each parameter had in the loss value. The algorithm that computes the loss value is gradient descent. **Gradient descent** is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Since this is a beginning book, we won't delve deeper into how backpropagation works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZShpWX4No45s"
      },
      "source": [
        "# The Training Loop\n",
        "\n",
        "When data initially enters a neural network, its output is from from ideal. So, loss is very high. But, with every example the network processes the weights are adjusted a little in the correct direction. So, loss decreases. A **weight** refers to the strength of a connection between two nodes (or neurons). This cycle of repeatedly feeding the data into the network and adjusting weights is called the **training loop**.\n",
        "\n",
        "By repeating the training loop a sufficient amount of times, the network yields weights that minimize the loss function (or loss). A network with minimal loss is one with outputs that are very close to the targets. Such a network is called a **trained network**.\n",
        "\n",
        "When a neural network is running, it takes a data set, splits it into a bunch of tiny fragments, and disperses those fragments among all of the neurons contained within. The neurons take the data they receive, operate on it using the stored weight, and then pass on the resulting data to the output. At the end of processing, all of the outputs are aggregated to come to a conclusion. If the network is still being trained, this conclusion will be evaluated for correctness and then the weights of all the neurons involved will be adjusted slightly. These adjustments reduce the values of the ones that were wrong and increase the ones that were right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MmHHkv6nyW_d"
      },
      "source": [
        "\n",
        "\n",
        "# How Deep Learning Learns from Data\n",
        "\n",
        "Deep learning learns through incremental, layer-by-layer activity where increasingly complex representations are developed. Also, these intermediate incremental representations are learned jointly. That is, each layer is automatically updated to follow both the representational needs of the layer above and the needs of the layer below. Learning through **successive layers** and **learning jointly** make deep learning vastly more successful than previous approaches to machine learning.\n",
        "\n",
        "Before we can begin working with real deep learning examples, we need to explain the tensorflow package and the work space (Google Colab) that we will be working with throughout the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rIJBu6uZ9pgq"
      },
      "source": [
        "# TensorFlow 2.x\n",
        "\n",
        "**TensorFlow** is a Python open source library for numerical computation that was created to facilitate machine learning and deep learning problem solving. TensorFlow bundles together machine learning and deep learning models and algorithms and makes them useful by way of a common programming environment.\n",
        "\n",
        "In 2019, Google released a new version of their TensorFlow deep learning library (TensorFlow 2.x) that integrates the Keras API directly and promotes this interface as the default or standard interface for deep learning development on the platform. The integration between TensorFlow and Keras is commonly referred to as the **tf.keras** interface or API ('tf' is the abbreviation for 'TensorFlow').\n",
        "\n",
        "**Keras** is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Keras is extremely popular for building and training deep learning models.\n",
        "\n",
        "The Keras API was the obvious choice for integration with TensorFlow because it was clean and simple, which allowed standard deep learning models to be defined, fit, and evaluated in just a few lines of code. Another reason was because it allowed us to use popular deep learning mathematical libraries for backend computation such as TensorFlow, Theano, and CNTK. As a result, Keras could use the power of these libraries to be harnessed with a very clean and simple interface.\n",
        "\n",
        "The biggest change with Tensorflow 2.x is the integration of Keras layers and models to manage variables. Keras models and layers offer the convenient variables and trainable_variables properties to recursively gather up all dependent variables, which makes it easy to manage variables locally where they are being used.\n",
        "\n",
        "TensorFlow 2.x was introduced to make TensorFlow users more productive. TensorFlow 2.x removes redundant APIs, makes APIs more consistent, and better integrates with the Python runtime with Eager execution.\n",
        "\n",
        "**Eager execution** is a flexible machine learning platform for research and experimentation that provides an intuitive interface to help you structure your code naturally by using legacy Python data structures. It also allows you to quickly iterate on small models and small data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Q2LVSPU9SmE"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "**Google Colab** (short for Google Colaboratory) is a cloud-based data science work space similar to the jupyter notebook. Each **Colab** session is equipped with a virtual machine running 13 GB of ram and either a CPU, GPU, or TPU processor. The work space allows you to use and share Jupyter notebooks with others without having to download, install, or run anything on your own computer other than a browser.\n",
        "\n",
        "Colab is an exceptional research tool for machine learning education and research because it is free to use, mimics a Jupyter notebook environment, and requires no setup to use. It also provides GPU and TPU support for complex machine learning models that require heavy duty computing resources. GPU support is very easy to set and use. However, TPU support requires deep expertise because it is much more difficult to set up and use.\n",
        "\n",
        "Although Colab is based on the popular Jupyter open source project, the **interface** and **functionality** differ slightly. So, it may take you a minute to familiarize yourself with the product.\n",
        "\n",
        "The first time we worked with Colab, we visited the main site at: \n",
        "https://colab.research.google.com/notebooks/welcome.ipynb. The site offers a nice tutorial on using the product. But, you can browse and find numerous tutorials and YouTube videos on the topic to deepen your Colab skills. Actually, Jupyter Notebook aficionados should have little trouble adapting because Colab was developed based on the Jupyter project.\n",
        "\n",
        "Colab works with most major browsers. But, it is most thoroughly tested with the latest versions of Chrome, Firefox and Safari.\n",
        "\n",
        "Colaboratory notebooks are stored in Google Drive and can be shared as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colaboratory notebook, or follow these Google Drive file sharing instructions.\n",
        "\n",
        "For **all** of the programming material covered, we will be working in the Colab environment. Of course, you are free to work in any enviroment you wish. But, for readers new to TensorFlow 2.0 we strongly recommned working within the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ciDQqtJQnUwY"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "Google Drive is a cloud-based file storage and synchronization service developed by Google. It allows us to store files on their servers, synchronize files across devices, and share files. Google Drive encompasses Google Docs, Google Sheets, and Google Slides, which are a part of an office suite that permits collaborative editing of documents, spreadsheets, presentations, drawings, forms, and more. Files created and edited through the office suite are automatically saved in Google Drive. Fortunatley for us, Google Drive offers 15 gigabytes of free storage.\n",
        "\n",
        "## Connect Google Colab with Google Drive\n",
        "\n",
        "It just takes a few simple steps to connect Colab with Google Drive:\n",
        "\n",
        "1. Sign into your Google email account\n",
        "\n",
        "2. Open a new browser tab and browse to **Google Colab**\n",
        "\n",
        "3. Click the **Colab-Google** link\n",
        "\n",
        "4. Click **Google Drive** in the pop-up window\n",
        "\n",
        "5. Just click **CANCEL** since we haven't created any notebooks yet\n",
        "\n",
        "That's all there is to it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x0O_2-wwAj6t"
      },
      "source": [
        "# Create a Notebook\n",
        "\n",
        "Here are the steps to create a new Colab notebook:\n",
        "\n",
        "1. Open **Google Colab** in a browser (if you haven't already done so).\n",
        "\n",
        "2. Click the **File** tab (top-left)\n",
        "\n",
        "3. Click **New notebook** from the drop-down list\n",
        "\n",
        "Now, we are ready to begin working with Colab! We can just start typing our code and press the arrow symbol on the left to execute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0E-WAvDjBsa"
      },
      "source": [
        "# Download a File from a URL\n",
        "\n",
        "We can directly download a file from a URL with **tf.keras.utils.get_file**. But, we need TensorFlow for this task. Fortunately, Colab already has it preinstalled. Colab has two versions: a 2.x version and a 1.x version. Colab currently uses TensorFlow 2.x by default, but users can easily switch to 1.x. Consult the following URL for more information:\n",
        "\n",
        "https://colab.research.google.com/notebooks/tensorflow_version.ipynb#scrollTo=N2y2uqx9GfA5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kecafNRum-o_"
      },
      "source": [
        "## Check TensorFlow Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8a9ZupnlW0U",
        "outputId": "d1c59323-d438-45be-da10-9a03768f15b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import library\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2OKM8KxmnHJ0"
      },
      "source": [
        "## Download Data from a URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RV8urJAkkUbc",
        "outputId": "7ca7a7fa-6f68-4e1d-90c2-0b5129db4a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we need the keras module\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "ds = 'auto-mpg.data'\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "dataset_path = keras.utils.get_file(ds, url)\n",
        "dataset_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/auto-mpg.data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VRMG69usklIU"
      },
      "source": [
        "We just downloaded a dataset from the UCI Machine Learning Repository. The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. The archive was created as an ftp archive in 1987 by David Aha and fellow graduate students at UC Irvine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MNyg7TyEnpxI"
      },
      "source": [
        "## Prepare the Dataset\n",
        "\n",
        "As is, the dataset requires some preprocessing. For example, it is without feature headings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9X0EqXlQ_XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need the pandas library\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "        'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=cols,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OY8sn2_fqWyq"
      },
      "source": [
        "We begin by importing the pandas library. We continue by creating a variable to hold the feature names for each column. We then create a Pandas DataFrame with the **read_csv()** method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfZjfiGtSNy9",
        "colab_type": "text"
      },
      "source": [
        "Let's see what we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drxTwfPXSQfb",
        "colab_type": "code",
        "outputId": "3c44393b-5244-4569-babc-a8c5199f6032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  ...  Acceleration  Model Year  Origin\n",
              "393  27.0          4         140.0  ...          15.6          82       1\n",
              "394  44.0          4          97.0  ...          24.6          82       2\n",
              "395  32.0          4         135.0  ...          11.6          82       1\n",
              "396  28.0          4         120.0  ...          18.6          82       1\n",
              "397  31.0          4         119.0  ...          19.4          82       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELnDrtJOnsft",
        "outputId": "07abe9d6-62de-4259-fc1d-9fe3c8f45df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# create a copy\n",
        "\n",
        "data = raw_dataset.copy()\n",
        "\n",
        "# display some data\n",
        "\n",
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  ...  Acceleration  Model Year  Origin\n",
              "393  27.0          4         140.0  ...          15.6          82       1\n",
              "394  44.0          4          97.0  ...          24.6          82       2\n",
              "395  32.0          4         135.0  ...          11.6          82       1\n",
              "396  28.0          4         120.0  ...          18.6          82       1\n",
              "397  31.0          4         119.0  ...          19.4          82       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iHuZHKTTVZ3",
        "colab_type": "text"
      },
      "source": [
        "We create a copy of the original DataFrame in case we need the original data. We end by displaying the last five records with the **tail()** method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fHlK1brH3Uvb"
      },
      "source": [
        "# Colab Abends\n",
        "\n",
        "An AbEnd (also abnormal end or abend) is an abnormal termination of software or a program crash. The term goes way back to an error message from the IBM OS/360, which used the IBM zOS operating systems.\n",
        "\n",
        "Since Colab is free, we can't expect it to be perfect for our needs. We've noticed that when we run Colab for a long time (several hours) without pause or read a large dataset into memory and process said data, it has the tendency to crash (or abend). When this happens, you have two choices that we know of:\n",
        "\n",
        "1. Restart runtime.\n",
        "\n",
        "2. Close the program and restart it from scratch.\n",
        "\n",
        "To restart runtime, click **Runtime** on the top menu, click **Restart runtime...**, and click **Yes** when prompted. Colab recommends this option. To restart from scratch, clear browser history first and then start Colab from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXINq3f6b1Xu"
      },
      "source": [
        "# Colab Strange Results\n",
        "\n",
        "We've noticed that sometimes we get errors and other strange results when working with Colab. If you are getting unexpected errors or results, just restart the runtime (just like in the **Colab Abends** section) for the notebook you are working on. And, rerun your notebook from the beginning.\n",
        "\n",
        "Don't be shy to restart runtime. We've been working with Colab for quite some time and find that Colab can act strangely, especially when running when processing complex models and/or being used for a long time. Everytime we've restarted runtime, it has acted as expected. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WYZcfpmW734U"
      },
      "source": [
        "# Tensors\n",
        "\n",
        "A **tensor** is a container for *numeric* data. Tensors can contain data within an arbitrary number of dimensions. That is, it can be a zero-dimensional (0D), one-dimensional (1D), two-dimensional (2D), three-dimensional (3D), and so on. Within the context of tensors, a dimension is often called an **axis**.\n",
        "\n",
        "So, tensors are a generalization of matrices represented by n-dimensional arrays. The dimensionality of a tensor is often described by its number of axes. The number of axes represented by a tensor is called its **rank**. Tensors are defined by how many axes they have in total.\n",
        "\n",
        "## Scalars (0D tensors)\n",
        "\n",
        "A **scalar** is a tensor of only one number. For example, a Numpy float32 or float64 number is a scalar tensor (or scalar array).\n",
        "\n",
        "It is easy to dispay the number of axes (or dimensionality) of a Numpy tensor with the *ndim* attribute. Let's look at an example of a Numpy scalar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a27HcC6ysOPW",
        "outputId": "4928bb8e-0b71-49f2-a70b-b67754fc386e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# create a numpy scalar\n",
        "\n",
        "scalar = np.array(9)\n",
        "scalar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rdbxT4dGsi3Q",
        "outputId": "487e503d-0fee-4edc-e330-e12721579ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# signal its rank\n",
        "\n",
        "print (str(scalar.ndim) + 'D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s0bWPuPR8NQk"
      },
      "source": [
        "## Vectors (1D tensors)\n",
        "\n",
        "A **vector** is an array of numbers. So, a vector is a 1D tensor. A 1D tensor has exactly one axis.\n",
        "\n",
        "Let's look at an example of a Numpy vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6Tm4QKtt0wa",
        "outputId": "80ba8479-f9ad-484d-9500-a83731837105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a numpy vector\n",
        "\n",
        "vector = np.array([0, 1, 0, 0, 0, 0])\n",
        "vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5u1SlYbuD0Q",
        "outputId": "ce2ed859-3afc-4170-ff56-336067675f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# signal its rank\n",
        "\n",
        "print (str(vector.ndim) + 'D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YW21-kVMuar4"
      },
      "source": [
        "## Matrices (2D tensors)\n",
        "\n",
        "A **matrix** is an array of vectors. So, a matrix is a 2D tensor. A 2D tensor (or matrix) has two axes. Its axes are generally referred to a *rows* and *columns*.\n",
        "\n",
        "Let's look at an example of a Numpy matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bjnm7oUHu-Of",
        "outputId": "e7e88ab7-8f1d-4d3f-ab72-70159dd70f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# create a numpy matrix\n",
        "\n",
        "matrix = np.array([[0, 1, 0, 0, 0, 0],\n",
        "                   [0, 0, 1, 0, 0, 0],\n",
        "                   [0, 0, 0, 1, 0, 0],\n",
        "                   [0, 0, 0, 0, 1, 0],\n",
        "                   [0, 0, 0, 0, 0, 1]])\n",
        "matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0l5wKVtIvAYH",
        "outputId": "34e25695-bb6f-4394-d9cd-25ec2c12d0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# signal its rank\n",
        "\n",
        "print (str(matrix.ndim) + 'D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i2QCrBQ_wgsJ"
      },
      "source": [
        "**Rows** are the entries from the first axis and **columns** are the entries from the second axis. So, the first row from our example is [0, 1, 0, 0, 0, 0] and the first column is [0, 0, 0, 0, 0, 0]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAoEVC3nv-TU"
      },
      "source": [
        "## 3D tensors and beyond\n",
        "\n",
        "We can create a 3D tensor by packing 2D tensors (or matrices) into a new array. A 3D tensor can be visually interpreted as a cube of numbers.\n",
        "\n",
        "Let's look at an example of a Numpy 3D tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju__j0XGkAT2",
        "colab_type": "code",
        "outputId": "7764efc9-29f1-40b3-f18f-c35d6b030974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a 3D tensor\n",
        "\n",
        "D3 = np.array([[[0, 1, 2]],\n",
        "               [[3, 4, 5]],\n",
        "               [[6, 7, 8]]])\n",
        "\n",
        "# signal its rank\n",
        "\n",
        "print (str(D3.ndim) + 'D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3D\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VY4-yZLpyl7E"
      },
      "source": [
        "By packing 3D tensors into an array, you can create 4D tensors and so on. In deep learning, we generally manipulate tensors that are 0D to 4D. With video processing, we can go up to 5D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mkkx_iQjzG7i"
      },
      "source": [
        "# Key Attributes of a Tensor\n",
        "\n",
        "1. rank\n",
        "2. shape\n",
        "3. data type\n",
        "\n",
        "As discussed earlier, the **rank** of a tensor is its number of axes. A 1D tensor has one axis, a 2D tensor has two axes, and a 3D tensor has three axes.\n",
        "\n",
        "The **shape** of a tensor is a tuple of integers that describe the number of dimensions it has along each axis. So, our 3D matrix has shape (3, 1, 3), 2D matrix has shape (5, 6), vector has shape (6,) and scalar has an empty shape ().\n",
        "\n",
        "Let's prove this with examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k01eWCntz_0-",
        "outputId": "98cc412b-003d-477c-ef15-42e4a443431e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 3 instances of 1 x 3 matrices\n",
        "\n",
        "D3.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GVB4U9Edz8U2",
        "outputId": "e5df997d-6352-4254-a6a3-7ba3371f707e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 5 rows and 6 columns (or 5 x 6 matrix)\n",
        "\n",
        "matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CmFzK8R70VY_",
        "outputId": "40a839ae-7a00-476e-e663-187cb81a9ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 6 element vector\n",
        "\n",
        "vector.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yTggPWrk0W9H",
        "outputId": "c1611abc-1085-4903-c22f-54b3ba9a8f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# just a scalar number\n",
        "\n",
        "scalar.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xLx6FBoV1WE9"
      },
      "source": [
        "The **data type** is the type of data contained in the tensor. In Python, the data type is usually called *dtype*. Let's see data types of our tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9nNEjWv21sTT",
        "outputId": "af99f9e5-f95d-4588-82ca-e82489c86d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# dtype of tensors\n",
        "\n",
        "print (scalar.dtype)\n",
        "print (vector.dtype)\n",
        "print (matrix.dtype)\n",
        "print (D3.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCNxR40ZEzW",
        "colab_type": "text"
      },
      "source": [
        "# Input Pipelines\n",
        "\n",
        "An **input pipeline** is a sequence of data processing components that manipulate and apply data transformations. Pipelines are very common in machine learning and deep learning systems because these systems are data-rich. That is, they demand large volumes of data to perform. Input pipelines are the best way to transform large datasets because they break down processing into manageable components.\n",
        "\n",
        "Each component of an input pipeline pulls in a large amount of data, processes it in some manner, and spits out the result. The next component pulls in the resultant data, processes it in another manner, and spits out its own output. The pipeline continues until all of its components have finished their work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dEoNI_po9UKH"
      },
      "source": [
        "# The tf.data API\n",
        "\n",
        "The tf.data API revolves around the concept of a dataset, which represents a sequence of data items. Let's create our first TensorFlow dataset now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZdpUPytIoqkm"
      },
      "source": [
        "Let's create a simple 1D dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y3HtZLbM-Hno",
        "outputId": "baeb1943-abae-447c-8047-061e88782775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = tf.range(5)\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_k2NaBTwBp8"
      },
      "source": [
        "The dataset is a vector with five NumPy *int32* values ranging from 0 to 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ctuDHz-NUmN",
        "colab_type": "text"
      },
      "source": [
        "We can easily display actual values from the TensorFlow tensor we just created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsveQmXhL8Wo",
        "colab_type": "code",
        "outputId": "c9f4676c-57da-489b-fa0c-b567e0f4bb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaHfl4kmH7xT",
        "colab_type": "text"
      },
      "source": [
        "We can also access individual elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc-MqgAdH76I",
        "colab_type": "code",
        "outputId": "9757dc46-6506-4129-bc54-b06a80e3db94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# first element from tensor\n",
        "\n",
        "X[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyCfDxI6Imga",
        "colab_type": "text"
      },
      "source": [
        "Or, slice multiple elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT46w49FImpv",
        "colab_type": "code",
        "outputId": "f0acb6bc-023c-4d73-eec3-9ca8909ab0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 2nd, 3rd, and 4th elements from tensor\n",
        "\n",
        "X[1:4].numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYFNDrCoBIOt"
      },
      "source": [
        "# Function 'from_tensor_slices'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ixkW5cPq-f3C"
      },
      "source": [
        "Let's convert the dataset to a TensorFlow dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kN-4Tods-4K0",
        "outputId": "8f19405e-ddb6-40e8-9b83-7a4b6738a9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RohXPYT1_IVr"
      },
      "source": [
        "The **from_tensor_slices** functions takes a tensor and creates a **tf.data.Dataset** whose elements are all the slices of **X** (along the first dimension). We'll talk a lot more about TFDS data in the next chapter. Of course **X** only has one dimension! So, **dataset** contains five items, namely, tensors 0 to 4. Notice that the shape is '()', which indicates that the elements are scalars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hhDkdK7dBUcK"
      },
      "source": [
        "# Iterate a tf.data.Dataset\n",
        "\n",
        "We can simply iterate over the dataset items as so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zIfbIphqAPg1",
        "outputId": "10f58f85-1231-4700-f21d-ec3abae0ca9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for item in dataset:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUozYNXjAVuV"
      },
      "source": [
        "Alternatively, we could have created the TensorFlow dataset directly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zL-AOsYFAa49",
        "outputId": "bdfbba98-5dba-4fd0-9ade-ae70e8c60991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "for item in dataset:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "avHXXdqpA5Lm"
      },
      "source": [
        "However, notice that the **dtype** is *int64* rather than *int32*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "URzX4sTlG14r"
      },
      "source": [
        "# Tensors and Numpy\n",
        "\n",
        "Tensors play nice with Numpy. We can create a tensor from a NumPy array and vice versa. We can even apply TensorFlow operations to NumPy arrays and NumPy operations to tensors. Let's create a numpy array from the TensorFlow dataset that we just created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1OQkATm4HTrZ",
        "outputId": "fd58b658-d028-4da5-ec79-abe21da860da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# create a variable to hold a line break\n",
        "\n",
        "br = '\\n' # this is just a convenient way to include a line break\n",
        "\n",
        "# import NumPy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# technique 1\n",
        "\n",
        "ls = []\n",
        "for item in dataset:\n",
        "  e = item.numpy()\n",
        "  ls.append(e)\n",
        "\n",
        "np_arr = np.asarray(ls, dtype=np.float32)\n",
        "print (type(np_arr))\n",
        "print (np_arr, br)  \n",
        "\n",
        "# technique 2\n",
        "\n",
        "ls = [item.numpy() for item in dataset]\n",
        "np_arr = np.asarray(ls, dtype=np.float32)\n",
        "\n",
        "print (type(np_arr))\n",
        "print (np_arr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[0. 1. 2. 3. 4.] \n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "[0. 1. 2. 3. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qAr-nHq4KYwz"
      },
      "source": [
        "Use the **numpy()** method to create a numpy array from a TensorFlow dataset.The first technique uses a conventional Python loop. The second technique uses list comprehension, which takes fewer lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Is9gr-t2K8Qj"
      },
      "source": [
        "We can convert the numpy array back to a TensorFlow dataset with the **constant** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJ58gbipK1nP",
        "outputId": "9b3bc79d-b148-4c5b-8553-28233371d495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf_arr = tf.constant(np_arr)\n",
        "tf_arr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 2., 3., 4.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nLS46QP0LUs6"
      },
      "source": [
        "However, constants are immutable. That is, their values cannot be modified. So, we can use the **variable** method if we need to modify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eU37QVIyLfgn",
        "outputId": "53e0ad95-c057-42b9-c631-23ca0bc96972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# use the 'np_arr' list we just created\n",
        "\n",
        "tf_arr = tf.Variable(np_arr)\n",
        "tf_arr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 1., 2., 3., 4.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rcGMnps0x8gS"
      },
      "source": [
        "# Chaining Transformations\n",
        "\n",
        "We can apply transformations to a tf.data.Dataset by calling its transformation methods. Each method returns a **new** dataset, which allows us to chain transformations. Let's start with a single transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa2an1kAi5mE",
        "colab_type": "text"
      },
      "source": [
        "Create a tf.data.Dataset and show its values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bhvPwJyqy9jf",
        "outputId": "e8ad4c06-e71c-4ac3-a281-820b85cf4f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "\n",
        "for item in dataset:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lmc3lQZlH9Y",
        "colab_type": "text"
      },
      "source": [
        "We see that *dataset* contains values [0, 1, 2, 3, 4]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Jm-ubqi0bl",
        "colab_type": "text"
      },
      "source": [
        "Use the **repeat()** transformation method to add data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuYgSmWmi0iu",
        "colab_type": "code",
        "outputId": "ba9f0192-dea3-41ad-ce8f-984d00f1ffbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "data_rep = dataset.repeat(3)\n",
        "\n",
        "for item in data_rep:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Ks3OBNjWyA",
        "colab_type": "text"
      },
      "source": [
        "The new dataset contains three sets of the original. In deep learning, we can repeat data to enlarge a dataset for better performance without getting new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AWOaHshc1PiQ"
      },
      "source": [
        "Now, let's chain transformations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnR6QnQ32U25",
        "outputId": "b5ceb7d1-8a6f-405b-bdb0-78d75d16c8b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_batch = dataset.repeat(3).batch(7)\n",
        "\n",
        "for item in data_batch:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 0 1], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 3 4 0 1 2 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCVFLsij2d0Y"
      },
      "source": [
        "What happened? The first transformation, **repeat(3)**, creates three copies of the original dataset. We chain the first transformation into the second with **batch(7)**, which creates batches of seven items from the dataset.\n",
        "\n",
        "So, the new dataset contains three tensors. The first tensor contains \\[0, 1, 2, 3, 4, 0, 1], the second tensor contains \\[2, 3, 4, 0, 1, 2, 3], and the third tensor contains \\[4]. By the time we get to the third batch, we run out of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JWPRm0BB6f-Q"
      },
      "source": [
        "We can drop the final batch as so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yISKaTU22cup",
        "outputId": "28fc04b0-263c-4937-b170-9a69a03f6c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_drop = dataset.repeat(3).batch(7, drop_remainder=True)\n",
        "\n",
        "for item in data_drop:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 0 1], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 3 4 0 1 2 3], shape=(7,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0z2cUMwF7Ixs"
      },
      "source": [
        "Dataset methods don't modify datasets, they create new ones. So, we can keep track of each dataset by naming them differently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOZR6fyK9l-X"
      },
      "source": [
        "We can create equal batches as so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4u4SjEmf9u6A",
        "outputId": "ecf2d224-5564-40fc-c047-bae23618f1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_equal = dataset.repeat(3).batch(5)\n",
        "\n",
        "for item in data_equal:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U6Uz73D57uYA"
      },
      "source": [
        "# Mapping Tensors\n",
        "\n",
        "We can transform items in a tensor with the **map()** method. Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oPxw-yxN8BUY",
        "outputId": "e49478c3-2eda-427b-abaf-1e19fa3ce7e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# create a dataset\n",
        "\n",
        "dataset = tf.data.Dataset.range(7)\n",
        "\n",
        "# repeat and batch it\n",
        "\n",
        "data_batch = dataset.repeat(3).batch(7)\n",
        "\n",
        "# display the batched dataset\n",
        "\n",
        "for row in data_batch:\n",
        "  print (row)\n",
        "\n",
        "# map() a function on it\n",
        "\n",
        "data_map = data_batch.map(lambda x: x ** 2)\n",
        "\n",
        "# display the first batch\n",
        "\n",
        "print ()\n",
        "for item in data_map.take(1):\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "\n",
            "tf.Tensor([ 0  1  4  9 16 25 36], shape=(7,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20235D7Y99eQ"
      },
      "source": [
        "We create a new dataset with values \\[0, 1, 2, 3, 4, 5, 6]. We chain the repeat transformation to the batch transformation. We square each item by mapping with a lamda function. A **lambda function** is a single-line function declared with no name that can have any number of arguments, but can only have one expression. Instead of iterating the entire dataset, we can take one or more samples with the **take()** method. In our case, we just take the first sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qbwSb989-kld"
      },
      "source": [
        "# Unbatch Data\n",
        "\n",
        "What if we want to unbatch a dataset? Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eL2eNJce_eFu",
        "outputId": "e438874b-7742-4848-ddee-096a2e163ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "\n",
        "data_batch = dataset.repeat(3).batch(7)\n",
        "\n",
        "for item in data_batch.take(1):\n",
        "  print (item)\n",
        "\n",
        "print ()\n",
        "\n",
        "data_unbatch = data_batch.unbatch()\n",
        "\n",
        "for item in data_unbatch.take(7):\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 0 1], shape=(7,), dtype=int64)\n",
            "\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZHYI8URoAibZ"
      },
      "source": [
        "We create a dataset, apply a chaining transformation, and display the first tensor with values \\[0, 1, 2, 3, 4, 0, 1]. We unbatch the dataset and display the first seven tensors. Notice that the first tensor from **data_batch** contains seven items and that each tensor from **data_unbatch** contains a single scalar value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfG5ofbfBJm3"
      },
      "source": [
        "# Filter a tf.data.Dataset\n",
        "\n",
        "We can also filter data with the **filter()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ylKHOFnh_27t",
        "outputId": "5e59abb3-3c6e-40f9-acc7-031d223a4390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# create a dataset\n",
        "\n",
        "dataset = tf.data.Dataset.range(7)\n",
        "\n",
        "# display the dataset\n",
        "\n",
        "for row in dataset:\n",
        "  print (row)\n",
        "\n",
        "# apply a filter\n",
        "\n",
        "data_filter = dataset.filter(lambda x: x < 6 and x > 3)\n",
        "\n",
        "print ()\n",
        "for item in data_filter:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "es-ul9DjEhUP"
      },
      "source": [
        "We see that **data_filter** only contains tensors with scalar values less than 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cmOqC02eE5wk"
      },
      "source": [
        "# Shuffling Data\n",
        "\n",
        "Deep learning algorithms work best when instances in the training set are independent and identically distributed. A simple way to ensure this is to shuffle instances with the **shuffle()** method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McXTfJC0tduv",
        "colab_type": "text"
      },
      "source": [
        " Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f4p1Js22GgtA",
        "outputId": "0387a6b8-14a2-4a6d-95f5-72f2497d2f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a dataset\n",
        "\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "print ('dataset has', len(list(dataset)), 'elements')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset has 30 elements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_fFlbQFtijE",
        "colab_type": "text"
      },
      "source": [
        "Shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfB2axgDds0t",
        "colab_type": "code",
        "outputId": "2793ddcf-8b2b-45e0-a168-a5ba7c3c8a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# shuffle data into batches of 7\n",
        "\n",
        "ds = dataset.shuffle(buffer_size=5).batch(7)\n",
        "\n",
        "for item in ds:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 1 3 0 4 6 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 8 2 7 5 4 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 5 0 3 2 9 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 4 3 6 7 6 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 1], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h5uIdxdeNYJ",
        "colab_type": "text"
      },
      "source": [
        "We get tensors of seven items because we set batch size to 7. Notice that the last tensor has only two elements. We have four tensors of size seven, which equals 28 elements. Since the dataset has 30 elements, we have two left over.\n",
        "\n",
        "We set buffer size to 5. So, Tensorflow keeps a buffer of the next five samples and randomly selects one those five samples. It then adds the next element to the buffer. Each sample contains a batch of data. So, each sample in our example contains seven elements because we set batch size to 7.\n",
        "\n",
        "Performance can be improved by experimenting with different buffer sizes. But, getting it right takes time and energy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sNw1xVFxpMw",
        "colab_type": "text"
      },
      "source": [
        "Once shuffle is applied to a dataset, each dataset iteration creates a new shuffle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wmcxJwuGvyU",
        "outputId": "1960a243-8b4c-4ff0-9a61-635f3127e5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# rerun to get a different shuffle\n",
        "\n",
        "for item in ds:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([3 5 1 6 2 8 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 0 3 0 7 5 1], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 4 6 0 9 7 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 6 3 7 8 2 1], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 4], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtU2fXCCe1Hz",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Math\n",
        "\n",
        "TensorFlow provides several operations for math computations with the tf.math module. Peruse https://www.tensorflow.org/api_docs/python/tf/math for all possible math operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MODmKUJqgO-9",
        "colab_type": "text"
      },
      "source": [
        "## Vector Tensors\n",
        "\n",
        "Let's create some data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJuUCxTUgPHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create data\n",
        "\n",
        "v1 = np.array([0, 1, 4, 8, 16])\n",
        "v2 = np.array([0, 3, 9, 27, 81])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkn1neKmdnx",
        "colab_type": "text"
      },
      "source": [
        "Convert numpy arrays to tensor constants and add:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ms6qrM3mduD",
        "colab_type": "code",
        "outputId": "683b66e7-cc3d-4fef-fd78-89d2fa8cba4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conv1 = tf.constant(v1)\n",
        "conv2 = tf.constant(v2)\n",
        "\n",
        "result = tf.add(conv1, conv2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 0,  4, 13, 35, 97])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWjKzZvipQb",
        "colab_type": "text"
      },
      "source": [
        "Convert numpy arrays to tensor variables and add:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChExnxjoipYg",
        "colab_type": "code",
        "outputId": "2614ca2b-272d-4105-accd-bc942058832b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "varv1 = tf.Variable(v1)\n",
        "varv2 = tf.Variable(v2)\n",
        "\n",
        "result = tf.add(varv1, varv2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 0,  4, 13, 35, 97])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH2ZQfUcjMJa",
        "colab_type": "text"
      },
      "source": [
        "Subtract tensor variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_cuL_zdjMPu",
        "colab_type": "code",
        "outputId": "6b6e9598-b6c8-4a93-d921-40e25c7d3523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = tf.subtract(varv2, varv1)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 0,  2,  5, 19, 65])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R37jsqDhj-d1",
        "colab_type": "text"
      },
      "source": [
        "Mix constants and variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC3UJ2Oej-pn",
        "colab_type": "code",
        "outputId": "ad3db3e8-27c8-44ba-e14f-6c027a5469e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = tf.add(conv1, varv2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 0,  4, 13, 35, 97])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnLj8QsbkMfR",
        "colab_type": "text"
      },
      "source": [
        "Equivalency:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7NmRWEIkMmw",
        "colab_type": "code",
        "outputId": "aafc6e9c-dc9c-4345-85c6-efec4e8cc7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = tf.equal(varv1, varv2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=bool, numpy=array([ True, False, False, False, False])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUqD1MK0kiit",
        "colab_type": "text"
      },
      "source": [
        "Multiply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vUFnng4kira",
        "colab_type": "code",
        "outputId": "50397989-3d72-4a46-f6ab-9f3dfa50c4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = tf.multiply(conv1, conv2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([   0,    3,   36,  216, 1296])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT3uCqt-nVFQ",
        "colab_type": "text"
      },
      "source": [
        "Divide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFkrxcIOnVMm",
        "colab_type": "code",
        "outputId": "422d0122-f16d-400a-ab6d-bf77fd2309a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = tf.divide(conv2, 3)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float64, numpy=array([ 0.,  1.,  3.,  9., 27.])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9fc6HejcjY3",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQnHLVUQcjhw",
        "colab_type": "code",
        "outputId": "f487d986-64d2-4420-9ac7-82843887df0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create data\n",
        "\n",
        "m1 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "m2 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "\n",
        "m1.shape, m2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 3), (3, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl6pa_4pe2Fw",
        "colab_type": "text"
      },
      "source": [
        "Convert numpy matrices to tensors and add:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGHSyApge2Oe",
        "colab_type": "code",
        "outputId": "7cc09830-50d1-4573-b8b2-91c6f6c2062f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "conm1 = tf.constant(m1)\n",
        "conm2 = tf.constant(m2)\n",
        "\n",
        "result = tf.add(conm1, conm2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
              "array([[2, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 0, 2]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPwWLOV_h7WA",
        "colab_type": "text"
      },
      "source": [
        "Equivalency:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QdWuI8eh7bh",
        "colab_type": "code",
        "outputId": "00f1ac3f-4c6d-4fc6-c30f-0bebc664da8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "result = tf.equal(conm1, conm2)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
              "array([[ True,  True,  True],\n",
              "       [ True,  True,  True],\n",
              "       [ True,  True,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9f5MVmyqaKT",
        "colab_type": "text"
      },
      "source": [
        "## tf.data.Dataset Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBPcKM8BtiZD",
        "colab_type": "text"
      },
      "source": [
        "Create a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-OuufkCqaSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dataset\n",
        "\n",
        "m = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5ySUiy3uJG2",
        "colab_type": "text"
      },
      "source": [
        "Convert numpy matrix to a tf.data.Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA9ujJLTuJNX",
        "colab_type": "code",
        "outputId": "b9b0a304-50b8-4666-eed6-ab3cab174352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(m)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (4,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yAMVDAxviRz",
        "colab_type": "text"
      },
      "source": [
        "Display tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM-15N_svibK",
        "colab_type": "code",
        "outputId": "e43eedc1-6dc6-4f8b-b6f6-a28d3bf0603e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "for t in dataset:\n",
        "  print (t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int64)\n",
            "tf.Tensor([5 6 7 8], shape=(4,), dtype=int64)\n",
            "tf.Tensor([ 9 10 11 12], shape=(4,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvonmm0Zvryv",
        "colab_type": "text"
      },
      "source": [
        "Transform tensor values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHxqwPKpvr7A",
        "colab_type": "code",
        "outputId": "164287bf-13f7-4c3c-aa56-c70b92c3f0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "squared_data = dataset.map(lambda x: x ** 2)\n",
        "\n",
        "# display tensors\n",
        "\n",
        "for item in squared_data:\n",
        "  print (item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 1  4  9 16], shape=(4,), dtype=int64)\n",
            "tf.Tensor([25 36 49 64], shape=(4,), dtype=int64)\n",
            "tf.Tensor([ 81 100 121 144], shape=(4,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRTA2HuwNwWb",
        "colab_type": "text"
      },
      "source": [
        "# Save a Notebook\n",
        "\n",
        "Although **Autosave** is implemented in Google Colab, there is a delay between the moment you execute a cell and when the save occurs. So, we recommend periodically saving.\n",
        "\n",
        "1. Click **File** in the top left menu\n",
        "2. Click **Save** in the drop-down menu "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHT6b1teUrsj",
        "colab_type": "text"
      },
      "source": [
        "# Download a Notebook to a Local Drive\n",
        "\n",
        "Google Drive is an excellent place to store Colab notebooks. But, we also like to save notebooks to a local drive.\n",
        "Download a notebook to a local drive:\n",
        "1.\tBe sure to save the notebook\n",
        "2.\tClick **File** in the drop-down menu\n",
        "3.\tClick **Download .ipynb** in the drop-down menu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2xAGm7az2-2",
        "colab_type": "text"
      },
      "source": [
        "# Load a Notebook from a Local Drive\n",
        "\n",
        "We always save the most current notebook to our local drive because we have plenty of extra storage. We use Google Drive as backup because we only have 15 GB of free space. If you work for a company, they may provide extra storage. Given this case, you may want to use Google Drive for primary storage.\n",
        "\n",
        "To load a notebook from a local drive:\n",
        "1. Open **Google Colab**\n",
        "2. On the pop-up menu, click **Upload**\n",
        "3. Click **Choose File**\n",
        "4. Locate the notebook on your local drive and open it"
      ]
    }
  ]
}